{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = [\n",
    "    \"ダーウィンの進化論は嘘です\",\n",
    "    \"バナナはおやつに入ります\",\n",
    "    \"地球は平面です\",\n",
    "    \"日本では応用数学科はまだまだ少ない方です\",\n",
    "    \"数学と数理科学の違いはなんですか\",\n",
    "    \"散歩をするとバナナがおやつに入らないかもしれないことに気づきました\",\n",
    "    \"地球の半径を数理的に求めることができます\",\n",
    "    \"私はバナナが好きな数学者です\",\n",
    "    \"数学とバナナは同じです\",\n",
    "    \"残念ながら、地球とバナナとゴリラは同じではありません\",   #10\n",
    "    \"ダーウィンはバナナをおやつと考えました\",\n",
    "    \"これ以上無意味な文章を作ることをやめませんか\",\n",
    "    \"数理の世界は長い年月を経て進歩してきましたが、人間は長い年月を経てゴリラに近づきました\",\n",
    "    \"ダーウィンは進化論の提唱者ですが、ダテミキオはカロリー0理論の提唱者です\",\n",
    "    \"その理論を応用することで、バナナを用いてブラックホールを生成する方法を数学的に導くことができます\",\n",
    "    \"ピザはその高さを0に近づけることで体積が0に近づくためカロリーは0\",\n",
    "    \"ダーウィンはゴリラの進化元です\",\n",
    "    \"バナナのカロリーは1本86キロカロリーです\",\n",
    "    \"どうして地球にはピザが自生していないのですか\",\n",
    "    \"ここまでだいたい嘘\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDAの使用\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/vectordb/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/vectordb/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/vectordb/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1578: UserWarning: cumsum_out_mps supported by MPS on MacOS 13+, please upgrade (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1699313532615/work/aten/src/ATen/native/mps/operations/UnaryOps.mm:406.)\n",
      "  incremental_indices = (torch.cumsum(mask, dim=1).type_as(mask) + past_key_values_length) * mask\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 日本語に強そうなモデルを指定\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "# 20行のセンテンスを768次元のベクトルに変換（埋め込み）\n",
    "all_embeddings = model.encode(all_sentences)\n",
    "all_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qwen.tiktoken: 100%|██████████| 2.56M/2.56M [00:01<00:00, 2.35MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\xe3\\x83\\x80',\n",
       " b'\\xe3\\x83\\xbc\\xe3\\x82',\n",
       " b'\\xa6',\n",
       " b'\\xe3\\x82\\xa3',\n",
       " b'\\xe3\\x83\\xb3',\n",
       " b'\\xe3\\x81\\xae',\n",
       " b'\\xe9\\x80\\xb2',\n",
       " b'\\xe5\\x8c\\x96',\n",
       " b'\\xe8\\xab\\x96',\n",
       " b'\\xe3\\x81\\xaf',\n",
       " b'\\xe5\\x98\\x98',\n",
       " b'\\xe3\\x81\\xa7\\xe3\\x81\\x99']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizerでトークン化\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 指定したtokenizerを用いる\n",
    "tokenizer_rinna = AutoTokenizer.from_pretrained('rinna/nekomata-14b', device=device)\n",
    "\n",
    "all_tokens_rinna = [tokenizer_rinna.tokenize(sentence) for sentence in all_sentences]\n",
    "all_tokens_rinna[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
