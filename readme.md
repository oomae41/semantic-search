# 参考
## Pinecone
- [ベクトル特化型データベースサービス「Pinecone」でセマンティック・キーワード検索をやってみた | DevelopersIO](https://dev.classmethod.jp/articles/dive-deep-into-modern-data-saas-about-pinecone/#toc-3)
- [Pinecone Examples](https://docs.pinecone.io/page/examples)
    - [semantic-search.ipynb](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/semantic-search.ipynb)
- [Pinecone Datasets](https://docs.pinecone.io/docs/using-public-datasets)

## モデルリスト
- [nlp-waseda/roberta-base-japanese](https://huggingface.co/nlp-waseda/roberta-base-japanese)
- [sentence-transformers/paraphrase-multilingual-mpnet-base-v2 · Hugging Face](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2)
- [rinna/nekomata-14b](https://huggingface.co/rinna/nekomata-14b)

## その他記事
- [transformer](https://github.com/huggingface/transformers/blob/main/README_ja.md)
- [sentence transformersで日本語を扱えるモデルのまとめ – Yellowback Tech Blog](https://tech.yellowback.net/posts/sentence-transformers-japanese-models)
- [Tokenizer の違いによる日本語 BERT モデルの性能評価](https://www.anlp.jp/proceedings/annual_meeting/2021/pdf_dir/P4-12.pdf)
- [cl-tohoku/bert-base-japanese · Hugging Face](https://huggingface.co/cl-tohoku/bert-base-japanese)
- [トップ | e-Govデータポータル](https://data.e-gov.go.jp/info/ja)
- [【初心者向け】BERTのtokenizerについて理解する](https://zenn.dev/robes/articles/b6708032855a9c)
- [rinna社、日本語版GPT-2とBERTを無料公開 | DXを推進するAIポータルメディア「AIsmiley」](https://aismiley.co.jp/ai_news/rinna-jaoanese-nlp-gpt-2-bert/)